{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression: \n",
    "    - Predict the Remaining Useful Life (RUL), or Time to Failure (TTF).\n",
    "# Binary classification: \n",
    "    - Predict if an asset will fail within certain time frame (e.g. days).\n",
    "# Multi-class classification:\n",
    "    - Predict if an asset will fail in different time windows: E.g., fails in window [1, w0] days; fails in the window [w0+1,w1] days; not fail within w1 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import fileinput\n",
    "import re\n",
    "\n",
    "from io import StringIO\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"Data/PM_train.txt\"\n",
    "test_file = \"Data/PM_test.txt\"\n",
    "colnames = [\"id\",\"cycle\",\"setting1\",\"setting2\",\"setting3\",\"s1\",\"s2\",\"s3\",\"s4\",\"s5\",\"s6\",\"s7\",\n",
    "           \"s8\",\"s9\",\"s10\",\"s11\",\"s12\",\"s13\",\"s14\",\"s15\",\"s16\",\"s17\",\"s18\",\"s19\",\"s20\",\"s21\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_col_last(df,col_name):\n",
    "  return pd.concat([df.drop(col_name,axis=1),df[col_name]], axis=1)\n",
    "\n",
    "def move_col_first(df,col_name):\n",
    "  return pd.concat([df[col_name],df.drop(col_name,axis=1)], axis=1)\n",
    "\n",
    "def transfer_data(text_file_path,col_names):\n",
    "  # user defined variables to set the windows for classifcation\n",
    "  w1 = 30\n",
    "  w0 = 15\n",
    "  # window size (window_size>=2),  most recent sensor values\n",
    "  window_size = 5\n",
    "  \n",
    "  # read in the file\n",
    "  with open(train_file, 'r') as f:\n",
    "    filedata = f.read()\n",
    "  \n",
    "  # remove white space from the end of line\n",
    "  filedata = re.sub('\\s*$', '',filedata,flags = re.M)\n",
    "  \n",
    "  # filedata is a string that pretends to be a file input\n",
    "  file_as_string = StringIO(filedata)\n",
    "\n",
    "  dataset = pd.read_table(file_as_string,sep=\" \",names=colnames)\n",
    "  \n",
    "  # get the maximum cycle number for each id\n",
    "  d1 = dataset.groupby([\"id\"])[\"cycle\"].max().to_frame()\n",
    "  d1.columns = ['max']\n",
    "\n",
    "  # add column with the name 'id' (just copy the index)\n",
    "  d1['id'] = d1.index\n",
    "  d2 = pd.merge(dataset, d1, on='id')\n",
    "  \n",
    "  # generate the column RUL based on the values of columns \"max\" and \"cycle\"\n",
    "  d2['RUL'] = d2['max'] - d2['cycle']\n",
    "  \n",
    "  # exclude column \"max\" from the data frame\n",
    "  d2 = d2.drop('max', 1)\n",
    "\n",
    "  # genearte label1 and label2\n",
    "  dataset = d2\n",
    "  dataset['label1'] = np.where(d2['RUL'] <= w1, 1, 0)\n",
    "  dataset['label2'] = np.where(d2['RUL'] <= w0, 2, (np.where(d2['RUL'] <= w1,1,0)))\n",
    "  \n",
    "  # exclude comuns id, cycle, setting1,setting2,setting3, and last 3 columns\n",
    "  # only the 21 sensor columns are kept in the data frame\n",
    "  n_pre_sensor_columns = 5 # id, cycle, setting1,setting2,setting3\n",
    "  n_after_sensor_columns = 3 #RUL, label1, label2\n",
    "  n_col = len(dataset.columns)\n",
    "\n",
    "  data = dataset[dataset.columns[n_pre_sensor_columns:n_col - n_after_sensor_columns]]\n",
    "  n_sensor=len(data.columns)\n",
    "\n",
    "  ids = dataset.id.unique()\n",
    "  n_id = len(ids) # 100\n",
    "\n",
    "  a = [\"a\" + str(i) for i in range(1,n_sensor+1)] # average\n",
    "  sd = [\"sd\" + str(i) for i in range(1,n_sensor+1)] # standard deviation\n",
    "\n",
    "  df = None\n",
    "  for i in range(1,n_id+1):\n",
    "    # get the subset of the data that only contains the sensor columns for the id i\n",
    "    subset_rolling_mean = data[dataset.id==i].rolling(window_size,axis=0,min_periods=1).mean()\n",
    "    subset_rolling_mean.columns = a\n",
    "    subset_rolling_std = data[dataset.id==i].rolling(window_size,axis=0,min_periods=1).std().fillna(0)\n",
    "    subset_rolling_std.columns = sd\n",
    "    subset = pd.concat([subset_rolling_mean,subset_rolling_std], axis=1)\n",
    "    df1 = pd.concat([dataset[dataset.id == i],subset], axis=1)\n",
    "    df1 = move_col_last(df1,['RUL', 'label1','label2'])\n",
    "\n",
    "    if df is None:\n",
    "      df = df1\n",
    "    else:\n",
    "      df = df.append(df1,ignore_index=True)\n",
    "  df2 = df\n",
    "\n",
    "\n",
    "  # Exclude column names: id\n",
    "  df3 = df2.drop('id', 1)\n",
    "  df4 = df3.drop(['RUL','label1','label2'], 1)\n",
    "  \n",
    "  scaler = MinMaxScaler()\n",
    "  df5 = pd.DataFrame(scaler.fit_transform(df4), index=df4.index, columns=df4.columns)\n",
    "  \n",
    "  df6 = df5.dropna(axis=1)\n",
    "  \n",
    "  return df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the file\n",
    "with open(train_file, 'r') as f:\n",
    "  filedata = f.read()\n",
    "  \n",
    "# remove white space from the end of line\n",
    "filedata = re.sub('\\s*$', '',filedata,flags = re.M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = [\"id\",\"cycle\",\"setting1\",\"setting2\",\"setting3\",\"s1\",\"s2\",\"s3\",\"s4\",\"s5\",\"s6\",\"s7\",\n",
    "           \"s8\",\"s9\",\"s10\",\"s11\",\"s12\",\"s13\",\"s14\",\"s15\",\"s16\",\"s17\",\"s18\",\"s19\",\"s20\",\"s21\"]\n",
    "\n",
    "# filedata is a string that pretends to be a file input\n",
    "filedata = StringIO(filedata)\n",
    "\n",
    "dataset = pd.read_table(filedata,sep=\" \",names=colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the maximum cycle number for each id\n",
    "d1 = dataset.groupby([\"id\"])[\"cycle\"].max().to_frame()\n",
    "d1.columns = ['max']\n",
    "\n",
    "# add column with the name 'id' (just copy the index)\n",
    "d1['id'] = d1.index\n",
    "d2 = pd.merge(dataset, d1, on='id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the column RUL based on the values of columns \"max\" and \"cycle\"\n",
    "d2['RUL'] = d2['max'] - d2['cycle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude column \"max\" from the data frame\n",
    "d2 = d2.drop('max', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user defined variables to set the windows for classifcation\n",
    "w1 = 30\n",
    "w0 = 15\n",
    "\n",
    "# genearte label1 and label2\n",
    "dataset = d2\n",
    "dataset['label1'] = np.where(d2['RUL'] <= w1, 1, 0)\n",
    "dataset['label2'] = np.where(d2['RUL'] <= w0, 2, (np.where(d2['RUL'] <= w1,1,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude comuns id, cycle, setting1,setting2,setting3, and last 3 columns\n",
    "# only the 21 sensor columns are kept in the data frame\n",
    "n_pre_sensor_columns = 5 # id, cycle, setting1,setting2,setting3\n",
    "n_after_sensor_columns = 3 #RUL, label1, label2\n",
    "n_col = len(dataset.columns)\n",
    "\n",
    "data = dataset[dataset.columns[n_pre_sensor_columns:n_col - n_after_sensor_columns]]\n",
    "n_sensor=len(data.columns)\n",
    "\n",
    "ids = dataset.id.unique()\n",
    "n_id = len(ids) # 100\n",
    "\n",
    "a = [\"a\" + str(i) for i in range(1,n_sensor+1)] # average\n",
    "sd = [\"sd\" + str(i) for i in range(1,n_sensor+1)] # standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# window size (window_size>=2),  most recent sensor values\n",
    "window_size = 5\n",
    "df = None\n",
    "for i in range(1,n_id+1):\n",
    "  # get the subset of the data that only contains the sensor columns for the id i\n",
    "  subset_rolling_mean = data[dataset.id==i].rolling(window_size,axis=0,min_periods=1).mean()\n",
    "  subset_rolling_mean.columns = a\n",
    "  subset_rolling_std = data[dataset.id==i].rolling(window_size,axis=0,min_periods=1).std().fillna(0)\n",
    "  subset_rolling_std.columns = sd\n",
    "  subset = pd.concat([subset_rolling_mean,subset_rolling_std], axis=1)\n",
    "  df1 = pd.concat([dataset[dataset.id == i],subset], axis=1)\n",
    "  df1 = move_col_last(df1,['RUL', 'label1','label2'])\n",
    "  \n",
    "  if df is None:\n",
    "    df = df1\n",
    "  else:\n",
    "    df = df.append(df1,ignore_index=True)\n",
    "df2 = df\n",
    "\n",
    "\n",
    "# Exclude column names: id\n",
    "df3 = df2.drop('id', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3.drop(['RUL','label1','label2'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "df5 = pd.DataFrame(scaler.fit_transform(df4), index=df4.index, columns=df4.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = df5.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df = df6\n",
    "test_df = df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cycle</th>\n",
       "      <th>setting1</th>\n",
       "      <th>setting2</th>\n",
       "      <th>setting3</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>...</th>\n",
       "      <th>sd12</th>\n",
       "      <th>sd13</th>\n",
       "      <th>sd14</th>\n",
       "      <th>sd15</th>\n",
       "      <th>sd16</th>\n",
       "      <th>sd17</th>\n",
       "      <th>sd18</th>\n",
       "      <th>sd19</th>\n",
       "      <th>sd20</th>\n",
       "      <th>sd21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.459770</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.183735</td>\n",
       "      <td>0.406802</td>\n",
       "      <td>0.309757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00277</td>\n",
       "      <td>0.609195</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.283133</td>\n",
       "      <td>0.453019</td>\n",
       "      <td>0.352633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.488189</td>\n",
       "      <td>0.160656</td>\n",
       "      <td>0.508246</td>\n",
       "      <td>0.132258</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.017365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00554</td>\n",
       "      <td>0.252874</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.369523</td>\n",
       "      <td>0.370527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450405</td>\n",
       "      <td>0.120224</td>\n",
       "      <td>0.374753</td>\n",
       "      <td>0.116172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.169323</td>\n",
       "      <td>0.237961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00831</td>\n",
       "      <td>0.540230</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.256159</td>\n",
       "      <td>0.331195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.552267</td>\n",
       "      <td>0.133773</td>\n",
       "      <td>0.307559</td>\n",
       "      <td>0.427568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.234642</td>\n",
       "      <td>0.202745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01108</td>\n",
       "      <td>0.390805</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.349398</td>\n",
       "      <td>0.257467</td>\n",
       "      <td>0.404625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.481694</td>\n",
       "      <td>0.117620</td>\n",
       "      <td>0.267278</td>\n",
       "      <td>0.394651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.387298</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.226338</td>\n",
       "      <td>0.178837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cycle  setting1  setting2  setting3   s1        s2        s3        s4  \\\n",
       "0  0.00000  0.459770  0.166667       0.0  0.0  0.183735  0.406802  0.309757   \n",
       "1  0.00277  0.609195  0.250000       0.0  0.0  0.283133  0.453019  0.352633   \n",
       "2  0.00554  0.252874  0.750000       0.0  0.0  0.343373  0.369523  0.370527   \n",
       "3  0.00831  0.540230  0.500000       0.0  0.0  0.343373  0.256159  0.331195   \n",
       "4  0.01108  0.390805  0.333333       0.0  0.0  0.349398  0.257467  0.404625   \n",
       "\n",
       "    s5   s6    ...         sd12      sd13      sd14      sd15  sd16      sd17  \\\n",
       "0  0.0  1.0    ...     0.000000  0.000000  0.000000  0.000000   0.0  0.000000   \n",
       "1  0.0  1.0    ...     0.488189  0.160656  0.508246  0.132258   0.0  0.000000   \n",
       "2  0.0  1.0    ...     0.450405  0.120224  0.374753  0.116172   0.0  0.408248   \n",
       "3  0.0  1.0    ...     0.552267  0.133773  0.307559  0.427568   0.0  0.353553   \n",
       "4  0.0  1.0    ...     0.481694  0.117620  0.267278  0.394651   0.0  0.387298   \n",
       "\n",
       "   sd18  sd19      sd20      sd21  \n",
       "0   0.0   0.0  0.000000  0.000000  \n",
       "1   0.0   0.0  0.130435  0.017365  \n",
       "2   0.0   0.0  0.169323  0.237961  \n",
       "3   0.0   0.0  0.234642  0.202745  \n",
       "4   0.0   0.0  0.226338  0.178837  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df6\n",
    "y = df3['RUL']\n",
    "\n",
    "#Xt = test_df\n",
    "#yt = df3['RUL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(1)\n",
    "regr_1 = DecisionTreeRegressor(max_depth=16)\n",
    "regr_2 = AdaBoostRegressor(DecisionTreeRegressor(max_depth=4),n_estimators=300, random_state=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(base_estimator=DecisionTreeRegressor(criterion='mse', max_depth=4, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best'),\n",
       "         learning_rate=1.0, loss='linear', n_estimators=300,\n",
       "         random_state=<mtrand.RandomState object at 0x1121f0e58>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr_1.fit(X, y)\n",
    "regr_2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "y_1 = regr_1.predict(Xt[1:10])\n",
    "y_2 = regr_2.predict(Xt[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_2[4] \n",
    "yt[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
